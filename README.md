# ğŸ§˜ AI-Based Yoga Mudra Detection System

This project detects, analyzes, and corrects **Yoga Hand Mudras** in real time using AI and computer vision.

## ğŸ§  Features
- Real-time hand tracking with MediaPipe
- Mudra classification with Deep Learning
- Feedback system for correction
- Supports multiple users and poses

## âš™ï¸ Technologies
- Python 3.10+
- OpenCV, MediaPipe, TensorFlow, NumPy, Pandas
- VS Code for development

## ğŸ“ Project Structure

```text
YOGA-MUDRA/
â”‚
â”œâ”€â”€ checkpoints/                     # Trained model weights
â”‚   â”œâ”€â”€ feedback_model.pth
â”‚   â””â”€â”€ mudra_model_best.pth
â”‚
â”œâ”€â”€ data/                            # Dataset and processed files
â”‚   â”œâ”€â”€ images/                      # Captured + downloaded yoga hand mudra images
â”‚   â”œâ”€â”€ images_augmented/            # Augmented (AI-generated) images
â”‚   â”œâ”€â”€ landmarks/                   # Landmark data extracted using MediaPipe
â”‚   â”‚   â””â”€â”€ landmarks_clean.csv
â”‚   â””â”€â”€ preprocessed/                # Normalized and encoded training data
â”‚       â”œâ”€â”€ X.npy
â”‚       â”œâ”€â”€ y.npy
â”‚       â”œâ”€â”€ label_mapping.json
â”‚       â””â”€â”€ scaler.save
â”‚
â”œâ”€â”€ src/                             # Source code modules
â”‚   â”œâ”€â”€ capture/                     # Capture and prediction scripts
â”‚   â”‚   â”œâ”€â”€ capture_live.py          # Capture and label mudras manually
â”‚   â”‚   â”œâ”€â”€ capture_live_predict.py  # Real-time mudra prediction (model inference)
â”‚   â”‚   â””â”€â”€ capture_live_assistant.py# AI-based mudra assistant with feedback (audio + visual)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                      # Model training and architecture scripts
â”‚   â”‚   â”œâ”€â”€ train.py                 # Train mudra classification model
â”‚   â”‚   â””â”€â”€ train_feedback_models.py # Train feedback correction model
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/               # Data preparation and cleaning scripts
â”‚   â”‚   â”œâ”€â”€ augment_and_generate_landmarks.py  # Data augmentation + landmark generation
â”‚   â”‚   â”œâ”€â”€ clean_landmarks.py                # Clean raw landmark CSVs
â”‚   â”‚   â”œâ”€â”€ generate_landmarks_csv.py         # Generate landmark dataset from images
â”‚   â”‚   â””â”€â”€ normalize.py                      # Normalize and encode dataset for training
â”‚   â”‚
â”‚   â””â”€â”€ utils/                       # (Optional) helper utilities
â”‚
â”œâ”€â”€ venv/                            # Virtual environment (ignored in Git)
â”‚
â”œâ”€â”€ .gitignore                       # Ignored files/folders list
â”œâ”€â”€ README.md                        # Project documentation
â””â”€â”€ requirements.txt                 # Dependencies list


â–¶ï¸ How to Run

1. Activate your virtual environment

```bash .\venv\Scripts\activate


2. Run the live capture script to start collecting mudra data:

```bash python src/capture/capture_live.py user01


3. Run real-time AI assistant (for detection and feedback):

```bash python src/capture/capture_live_assistant.py

ğŸš€ Next Steps

 Collect additional dataset using MediaPipe

 Train and fine-tune MudraNet model for higher accuracy

 Integrate advanced AI-driven correction feedback

 Explore web or mobile deployment for wider usability

ğŸ§© Credits

Developed as part of an AI-driven Yoga Hand Mudra Assistant Project,
combining computer vision, deep learning, and wellness innovation.

âœ… Why this version is better:

âœ”ï¸ Clean headings and emoji icons
âœ”ï¸ Proper code block indentation
âœ”ï¸ Works beautifully on GitHubâ€™s markdown renderer
âœ”ï¸ Readable section spacing and professional layout