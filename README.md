# ðŸ§˜ AI-Based Yoga Mudra Detection System

This project detects, analyzes, and corrects **Yoga Hand Mudras** in real time using AI and computer vision.

## ðŸ§  Features
- Real-time hand tracking with MediaPipe
- Mudra classification with Deep Learning
- Feedback system for correction
- Supports multiple users and poses

## âš™ï¸ Technologies
- Python 3.10+
- OpenCV, MediaPipe, TensorFlow, NumPy, Pandas
- VS Code for development

## ðŸ“ Project Structure

```text
YOGA-MUDRA/
â”‚
â”œâ”€â”€ checkpoints/                     # Trained model weights
â”‚   â”œâ”€â”€ feedback_model.pth
â”‚   â””â”€â”€ mudra_model_best.pth
â”‚
â”œâ”€â”€ data/                            # Dataset and processed files
â”‚   â”œâ”€â”€ images/                      # Captured + downloaded yoga hand mudra images
â”‚   â”œâ”€â”€ images_augmented/            # Augmented (AI-generated) images
â”‚   â”œâ”€â”€ landmarks/                   # Landmark data extracted using MediaPipe
â”‚   â”‚   â””â”€â”€ landmarks_clean.csv
â”‚   â””â”€â”€ preprocessed/                # Normalized and encoded training data
â”‚       â”œâ”€â”€ X.npy
â”‚       â”œâ”€â”€ y.npy
â”‚       â”œâ”€â”€ label_mapping.json
â”‚       â””â”€â”€ scaler.save
â”‚
â”œâ”€â”€ src/                             # Source code modules
â”‚   â”œâ”€â”€ capture/                     # Capture and prediction scripts
â”‚   â”‚   â”œâ”€â”€ capture_live.py          # Capture and label mudras manually
â”‚   â”‚   â”œâ”€â”€ capture_live_predict.py  # Real-time mudra prediction (model inference)
â”‚   â”‚   â””â”€â”€ capture_live_assistant.py# AI-based mudra assistant with feedback (audio + visual)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                      # Model training and architecture scripts
â”‚   â”‚   â”œâ”€â”€ train.py                 # Train mudra classification model
â”‚   â”‚   â””â”€â”€ train_feedback_models.py # Train feedback correction model
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/               # Data preparation and cleaning scripts
â”‚   â”‚   â”œâ”€â”€ augment_and_generate_landmarks.py  # Data augmentation + landmark generation
â”‚   â”‚   â”œâ”€â”€ clean_landmarks.py                # Clean raw landmark CSVs
â”‚   â”‚   â”œâ”€â”€ generate_landmarks_csv.py         # Generate landmark dataset from images
â”‚   â”‚   â””â”€â”€ normalize.py                      # Normalize and encode dataset for training
â”‚   â”‚
â”‚   â””â”€â”€ utils/                       # (Optional) helper utilities
â”‚
â”œâ”€â”€ venv/                            # Virtual environment (ignored in Git)
â”‚
â”œâ”€â”€ .gitignore                       # Ignored files/folders list
â”œâ”€â”€ README.md                        # Project documentation
â””â”€â”€ requirements.txt                 # Dependencies list


### How to Run
1. Activate your virtual environment  
2. Run the capture script to start collecting data:
   \`\`\`
   python src/capture/capture_live.py user01
   \`\`\`

### Next Steps
- [ ] Collect dataset using MediaPipe
- [ ] Train baseline mudra classifier
- [ ] Add real-time correction feedback
" > README.md